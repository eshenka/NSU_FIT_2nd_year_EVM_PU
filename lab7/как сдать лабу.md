# Как сдать 7 лабу

Мой преподаватель сказал, что в этой лабе сильно много нужно сделать и он бы приступил к ней в последнюю очередь.

Самая ёмкая часть программы, на которую уходит больше всего времени, это перемножение матриц. Поэтому в каждом варианте лабораторной работы пытаемся оптимизировать именно эту операцию.

### Без ручной векторизации
Оптимизация, которая нам доступна, это предотвращение кэш-буксования и улучшение кэш-локальности. При умножении матриц обычно учат умножать строку на столбец. Так как, чтобы получить вектор столбца, необходимо обращаться к одному этому же элементу в разных строках матрицы, может возникнуть кэш-буксование (9-ая лаба), а так же мы обходим матрицу не последовательно (8-ая лаба), такой вариант будет работать *намного* дольше.

Поэтому намного лучше транспонировать вторую матрицу и накапливать суммы элементов. Подробнее реализацию можно рассмотреть в коде.

### С ручной векторизацией
Мной было принято решение взять код из описания лабораторной работы и расширить его с 128 до 256. Каждая функция переписывалась согласно зеркалу Intel'а на сайте ЭВМ.

Объяснять, что там происходит, очень тяжело, понимать еще сложнее. По сути мы сначала берем два вектора, перемножаем их элементы между собой. Теперь нужно просуммировать все элементы этого вектора.

Пусть нужные нам элементы лежат в векторе **A**. Заведем вспомогательный вектор **B**. В первые четыре элемента вспомогательного вектора сложим последние четыре элементы вектора **A**. Далее просуммируем эти векторы. И так будем делать до тех пор, пока не сложим все половинки друг с другом и их сумма не окажется в первом элементе вектора.

При 256 в векторе лежит 8 элементов.

Процесс суммирования выглядит так.
**A** = [a, b, c, d, e, f, g, h]
**B** = [0, 0, 0, 0, 0, 0, 0, 0]

**B** = [0, 0, 0, 0, a, b, c, d]
**A** = **A** + **B** = [a, b, c, d, a + e, b + f, g + c, h + d]
**B** = [a, b, c, d, a + e, b + f, a + e, b + f]
**A** = **A** + **B** = [.., .., .., .., .., .., a + e + g + c, b + f + h + d]
**B** = [.., .., .., .., .., .., .., a + e + g + c]
**A** + **B** = [.., .., .., .., .., .., .., *искомая нами сумма*]

Вопрос, который задают в этой части, это почему векторизация ускоряет время работы программы. Вообще такое может произойти не всегда, у меня при векторах на 4 элементах время работы наоборот увеличивалось.

Здесь важно говорить, что для процессора умножение векторов и просто умножение двух интов занимает одинаковое время, только во втором случае вы перемножите только два значимых элемента, а в первом уже 16. 

Так же могут спросить, когда вычисления вообще можно векторизовать. Необходимо, чтобы данные были одного типа и лежали в памяти последовательного, ни один элемент не зависел от другого, а так же, чтобы выполняемая над ними операция, была одинаковой. То есть если первую половину массива вы как-то перемножаете, а вторую как-то суммируете, эта операция не векторизуема. Умножение же матриц векторизуемая операция.

### OpenBLAS
Если вы на винде, копируете себе [этот](https://github.com/OpenMathLib/OpenBLAS) репозиторий, открываете его через GitBash, прописываете просто `make` (советую так же скачать с choco). После того, как библиотека сбилдилась, пишете там же `make PREFIX="директория новой папки для билиотеки" install`, после чего в директории появится три папки, их копируем и добавляем в файлы вашего компилятора (мной были добавлены в MinGW).

После этого спокойно будет работать `#include <blas>`. Команда для компиляции `g++ -O3 main.c -o main.exe -lopenblas`

Единственный вопрос, который задавали, это почему Blas быстро работает. Единственный ответ заключается в том, что библиотека просто сильно оптимизирована для подобных операций. Больше о ней можно узнать в интернете или во время разговора с преподавателем.




